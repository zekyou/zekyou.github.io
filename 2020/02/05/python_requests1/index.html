<!DOCTYPE HTML>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  
  <title>Python爬虫遇到YunSuoAutoJump跳转网页 | ZeKyou&#39;s Blog</title>
  <meta name="author" content="ZeKyou">
  
  <meta name="description" content="​        最近在搞一个自制的参考文献归档，查阅记录的工具。需要刚好需要用到Python爬虫，爬取Paper和References。国内由于谷歌学术无法访问，所以怕一个国内的网站，但基本就是一个国内的代理服务器，文献是结果一样的。不过在爬取过程过遇到了网址跳转的问题。">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="Python爬虫遇到YunSuoAutoJump跳转网页"/>
  <meta property="og:site_name" content="ZeKyou&#39;s Blog"/>

  
    <meta property="og:image" content=""/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="ZeKyou&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  

<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">ZeKyou&#39;s Blog</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/">Resource</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article id="post-python_requests1" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2020-02-04T15:00:00.000Z"><a href="/2020/02/05/python_requests1/">2020-02-05</a></time>
      
      
  
    <h1 class="p-name title" itemprop="headline name">Python爬虫遇到YunSuoAutoJump跳转网页</h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <div id="post-toc" class="post-toc" style="position: absolute; top:0px;">
    <div class="toc-title">目录</div>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#前情提要"><span class="toc-text">前情提要</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#过程"><span class="toc-text">过程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#一、给出Location"><span class="toc-text">一、给出Location</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#二、传递security-id"><span class="toc-text">二、传递security_id</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#三、获取security-mid-id"><span class="toc-text">三、获取security_mid_id</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#四、获取真正目标html"><span class="toc-text">四、获取真正目标html</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#简化"><span class="toc-text">简化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Location上的简化"><span class="toc-text">Location上的简化</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#预告"><span class="toc-text">预告</span></a></li></ol>
</div>

        
        <p>​        最近在搞一个自制的参考文献归档，查阅记录的工具。需要刚好需要用到Python爬虫，爬取Paper和References。国内由于谷歌学术无法访问，所以怕一个国内的网站，但基本就是一个国内的代理服务器，文献是结果一样的。不过在爬取过程过遇到了网址跳转的问题。<a id="more"></a></p>
<h1 id="前情提要"><a href="#前情提要" class="headerlink" title="前情提要"></a>前情提要</h1><p>​        在使用requests库爬取关键词时，返回来的并不是用浏览器获得的结果。</p>
<p>​        例如我们一般爬取搜索页面，输入参数seismic，通过Fiddler抓包发现网址是</p>
<blockquote>
<p><a href="http://so.hiqq.com.cn/scholar_complete.php?q=seismic&amp;hl=zh-CN&amp;as_sdt=0%2C5&amp;btnG=" target="_blank" rel="noopener">http://so.hiqq.com.cn/scholar_complete.php?q=seismic&amp;hl=zh-CN&amp;as_sdt=0%2C5&amp;btnG=</a> </p>
</blockquote>
<p>但是我们调用Requests库去Get请求，返回的不是想要的内容，而是</p>
<blockquote>
<p>HTTP/1.1 302 Moved Temporarily<br>Server: nginx<br>Date: Thu, 13 Feb 2020 13:54:15 GMT<br>Content-Type: text/html<br>Transfer-Encoding: chunked<br>Connection: keep-alive<br>Location: <a href="https://zz.glgoo.top/scholar?hl=zh-CN&amp;as_sdt=0%2C5&amp;q=seismic&amp;btnG=" target="_blank" rel="noopener">https://zz.glgoo.top/scholar?hl=zh-CN&amp;as_sdt=0%2C5&amp;q=seismic&amp;btnG=</a></p>
</blockquote>
<p>响应报文里没有响应体，头文件里就是一个类似重定向的东西，告诉我们，去这个Location找。这个倒是不难，直接再Request这个Location</p>
<h1 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h1><p>结果几次的摸索，算是搞清楚了整个过程，我以最一般的情况来说（不带有任何Cookies）。</p>
<h2 id="一、给出Location"><a href="#一、给出Location" class="headerlink" title="一、给出Location"></a>一、给出Location</h2><p>猜测是这个代理服务器存在很多个，域名基本都是</p>
<blockquote>
<p>xxx..glgoo.top/scholar</p>
<p>xxx.gufenxueshu.com/scholar</p>
</blockquote>
<p>每次都需要在kuaisou里给你一个门的钥匙。我们直接将此次Location的变量传给下一个Request</p>
<h2 id="二、传递security-id"><a href="#二、传递security-id" class="headerlink" title="二、传递security_id"></a>二、传递security_id</h2><p>对xxx.fufenxueshu.com/scholar的访问，首先会检测有没有Cookies，主要有4个参数</p>
<blockquote>
<p>UM_distinctid</p>
<p>_gads</p>
<p>security_session_verify</p>
<p>security_session_mid_verify</p>
</blockquote>
<p>前两个浏览器里可以直接获取，后两个，如果没有携带，则会分两次传递过来。本次Request获得了security_id,通过定义一个函数来获取参数并传递给下一个请求。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getssv</span><span class="params">(self,str)</span>:</span></span><br><span class="line">    strurl = self.geturl(<span class="number">0</span>,str)</span><br><span class="line">    headers=&#123;</span><br><span class="line">        <span class="string">'Referer'</span>: <span class="string">'http://so.hiqq.com.cn'</span>,</span><br><span class="line">        <span class="string">'Accept-Language'</span>: <span class="string">'zh-CN,zh;q=0.9'</span>,</span><br><span class="line">       <span class="comment"># "Accept-Language": "zh-Hans-CN,zh-Hans;q=0.8,ja;q=0.6,en-US;q=0.4,en;q=0.2",</span></span><br><span class="line">        <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36"</span>,</span><br><span class="line">        <span class="string">"Host"</span>: <span class="string">"xs.gufenxueshu.com"</span>,</span><br><span class="line">        <span class="string">"Connection"</span>: <span class="string">"keep-alive"</span>,</span><br><span class="line">        <span class="string">"Accept"</span>: <span class="string">"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9"</span>,</span><br><span class="line">        <span class="string">"Upgrade-Insecure-Requests"</span>: <span class="string">"1"</span>,</span><br><span class="line">        <span class="string">"Sec-Fetch-User"</span>: <span class="string">"?1"</span>,</span><br><span class="line">        <span class="string">"Sec-Fetch-Site"</span>: <span class="string">"cross-site"</span>,</span><br><span class="line">        <span class="string">"Sec-Fetch-Mode"</span>: <span class="string">"navigate"</span></span><br><span class="line">    &#125;</span><br><span class="line">            r1 = requests.get(strurl,headers = headers,verify=<span class="literal">False</span>)</span><br><span class="line">    ssv = r1.headers[<span class="string">'Set-Cookie'</span>]</span><br><span class="line">    ssv = re.findall(<span class="string">r'security_session_verify='</span><span class="string">'.&#123;32&#125;'</span>,ssv)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment">#print(ssv)</span></span><br><span class="line">    <span class="keyword">return</span> ssv</span><br></pre></td></tr></table></figure>

<h2 id="三、获取security-mid-id"><a href="#三、获取security-mid-id" class="headerlink" title="三、获取security_mid_id"></a>三、获取security_mid_id</h2><p>​        原理同上，不过这次请求需要带上上次给的ssv，同时，访问的站点后缀发生了一些变化。由于上次传来的响应体还包含了一个YunSuoAutoJump</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">xmlns</span>=<span class="string">"http://www.w3.org/1999/xhtml"</span>&gt;</span><span class="tag">&lt;<span class="name">head</span>&gt;</span><span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">"Content-Type"</span> <span class="attr">content</span>=<span class="string">"text/html; charset=UTF-8"</span>/&gt;</span><span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">"Cache-Control"</span> <span class="attr">content</span>=<span class="string">"no-store, no-cache, must-revalidate, post-check=0, pre-check=0"</span>/&gt;</span><span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">"Connection"</span> <span class="attr">content</span>=<span class="string">"Close"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span>&gt;</span></span><br><span class="line"><span class="actionscript"><span class="function"><span class="keyword">function</span> <span class="title">stringToHex</span><span class="params">(str)</span></span>&#123;</span></span><br><span class="line"><span class="actionscript">	<span class="keyword">var</span> val=<span class="string">""</span>;</span></span><br><span class="line"><span class="actionscript">	<span class="keyword">for</span>(<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; str.length; i++)&#123;</span></span><br><span class="line"><span class="actionscript">		<span class="keyword">if</span>(val == <span class="string">""</span>)</span></span><br><span class="line">			val = str.charCodeAt(i).toString(16);</span><br><span class="line"><span class="actionscript">		<span class="keyword">else</span> </span></span><br><span class="line">			val += str.charCodeAt(i).toString(16);</span><br><span class="line">	&#125;</span><br><span class="line"><span class="actionscript">	<span class="keyword">return</span> val;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="actionscript"><span class="function"><span class="keyword">function</span> <span class="title">YunSuoAutoJump</span><span class="params">()</span></span>&#123; </span></span><br><span class="line"><span class="actionscript">	<span class="keyword">var</span> width =screen.width; </span></span><br><span class="line"><span class="actionscript">	<span class="keyword">var</span> height=screen.height; </span></span><br><span class="line"><span class="actionscript">	<span class="keyword">var</span> screendate = width + <span class="string">","</span> + height;</span></span><br><span class="line"><span class="javascript">	<span class="keyword">var</span> curlocation = <span class="built_in">window</span>.location.href;</span></span><br><span class="line"><span class="actionscript">	<span class="keyword">if</span>(<span class="number">-1</span> == curlocation.indexOf(<span class="string">"security_verify_"</span>))</span></span><br><span class="line">		&#123; </span><br><span class="line"><span class="javascript">		<span class="built_in">document</span>.cookie=<span class="string">"srcurl="</span> + stringToHex(<span class="built_in">window</span>.location.href) + <span class="string">";path=/;"</span>;</span></span><br><span class="line">		&#125;</span><br><span class="line"><span class="actionscript">	self.location = <span class="string">"/scholar?hl=zh-CN&amp;as_sdt=0,5&amp;q=seismic&amp;btnG=&amp;oq=seismic&amp;security_verify_data="</span> + stringToHex(screendate);</span></span><br><span class="line">&#125;<span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="actionscript">setTimeout(<span class="string">"YunSuoAutoJump()"</span>, <span class="number">50</span>);</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span><span class="tag">&lt;/<span class="name">head</span>&gt;</span><span class="comment">&lt;!--2020-01-30 13:27:50--&gt;</span><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>​        分析不难发现，其实就是获取屏幕的分辨率（除去下方的任务栏），例如‘(1920,1080)’再通过一个函数，转化为十进制，我们写一个这样的转化函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stringToHex</span><span class="params">(self,string)</span>:</span></span><br><span class="line">    length = len(string)</span><br><span class="line">    hex_string = str()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(length):</span><br><span class="line">        hex_string += hex(ord(string[i]))[<span class="number">2</span>:]</span><br><span class="line">    <span class="keyword">return</span> hex_string</span><br></pre></td></tr></table></figure>

<p>​        后面只需要在原来的url后面加上</p>
<blockquote>
<p>&amp;security_verify_data=stringToHex(1920,1080)</p>
</blockquote>
<p>就可以获得ssmv了。</p>
<h2 id="四、获取真正目标html"><a href="#四、获取真正目标html" class="headerlink" title="四、获取真正目标html"></a>四、获取真正目标html</h2><p>​        在拿到两个认证Id后，添加到Cookies里，再回过头来访问原始url就可以正常拿到想要的html了。</p>
<h1 id="简化"><a href="#简化" class="headerlink" title="简化"></a>简化</h1><p>##　认证上的简化</p>
<p>​        其实在后续的请求中，发现有时候不需要ssv和ssmv也可以拿到完整的html，为了保持程序的完整性和速度，我们加一个判断就可以了，如果获取的ssv为空，就直接把这个request丢到beautifulsoup里，不用再去获取ssv和ssmv了。</p>
<h2 id="Location上的简化"><a href="#Location上的简化" class="headerlink" title="Location上的简化"></a>Location上的简化</h2><p>​        另外，其实在第一步获取Location时也可以省略，直接拿一个固定的服务器，不过这样的结果就是，如果这个服务器访问量太大，需要你刷新一下或者排队，也就是再次request一次。两种方法无非就是</p>
<ul>
<li>固定花费一定时间来到一个通畅的道路</li>
<li>不花费时间来到一个固定的道路，不过这个道路可能会堵塞</li>
</ul>
<h1 id="预告"><a href="#预告" class="headerlink" title="预告"></a>预告</h1><p>​        其实本次爬虫主要是为了一个自制的文献管理和记录的工具，后续我们会继续在PyQt中使用到这个类，完成我们对Paper和References的获取与记录。</p>

      
    </div>
    <footer>
      
        
  
  <div class="categories">
    <a href="/categories/计算机/">计算机</a>
  </div>

        
  
  <div class="tags">
    <a href="/tags/Python/">Python</a>
  </div>

        
  <div class="addthis addthis_toolbox addthis_default_style">
    
    
      <a class="addthis_button_tweet"></a>
    
    
      <a class="addthis_button_google_plusone" g:plusone:size="medium"></a>
    
    
      <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a>
    
    <a class="addthis_counter addthis_pill_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>

        
            <section id="comment" class="comment">
              <h1 class="title">Comments</h1>
              <div class="valine_comment"></div>
<!--载入js，在</body>之前插入即可-->
<!--Leancloud 操作库:-->
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<!--Valine 的核心代码库-->
<script src="//unpkg.com/valine/dist/Valine.min.js"></script>
<script>
  var notify = 'false' == true ? true : false;
  var verify = 'false' == true ? true : false;
  new Valine({
      // AV 对象来自上面引入av-min.js(老司机们不要开车➳♡゛扎心了老铁)
      av: AV,
      el: '.valine_comment',
      emoticon_url: 'https://cloud.panjunwen.com/alu',
      emoticon_list: ["狂汗.png","不说话.png","汗.png","坐等.png","献花.png","不高兴.png","中刀.png","害羞.png","皱眉.png","小眼睛.png","暗地观察.png"],
      app_id: 'wWOSPBUffJoJz5qeVL0drVLC-MdYXbMMI',
      app_key: 'VgDB2Nt89reberaVG9mddVDa',
      placeholder: 'I say...'
    });
</script>

          </section>
        

</div></div>
    
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2020 ZeKyou
  
</div>
<div class="clearfix"></div></footer>
  
<script src="/js/jquery-3.4.1.min.js"></script>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

  <!--loveclick --> 
  <script type="text/javascript" src="/js/love.js"></script>
  <!--funny title -->
  <script type="text/javascript" src="/js/FunnyTitle.js"></script>
  <!--toc -->
  <script type='text/javascript' src="/js/toc.js"></script>
</body>
</html>
